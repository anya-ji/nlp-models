import string
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords 

####### preprocess a list of tokens ########

"""
[preprocess] concatenates words with apostrophes and removes extraneous 
punctuations and stopwords. 
If [with_start] true, it adds <s> and </s> to the start and end of [tokens].
Precondition: [tokens] is a list of lowercased and tokenized words.
Returns: a list of word tokens by preprocessing [tokens].
"""
def preprocess(tokens, with_start = False):
  if with_start:
    return ['<s>'] + removeStopwords(cleanPunct(tokens)) + ['</s>']
  return removeStopwords(cleanPunct(tokens))


"""
[cleanPunkt] concatenates words with apostrophe and removes single punctuations 
and misplaced periods.
Precondition: [tokens] is a list of lowercased and tokenized words.
Returns: a list of word tokens without punctuation tokens.
"""
def cleanPunct(tokens):
  i = 0
  cleaned = []
 
  while i < len(tokens):
    
    if tokens[i]=="’":
      # "isn","'","t" --> "isn't"
      concat = tokens[i-1] + tokens[i] + tokens[i+1]
      if cleaned:
        del cleaned[-1]
        cleaned.append(concat)
        i += 1 # skip the next word
    
    elif tokens[i]=="t" or tokens[i]=="s" or tokens[i]=="re" or tokens[i]=="m" \
    or tokens[i]=="d" or tokens[i]=="ll" or tokens[i]=="ve":
      # "isn", "t" --> "isn't"
      concat = tokens[i-1] + "’" + tokens[i]
      if cleaned:
        del cleaned[-1]
        cleaned.append(concat)

    elif len(tokens[i])>1 and tokens[i][-1] == ".":
      # "embarrassment." --> "embarrassment"
      if tokens[i][:-1].strip():
        cleaned.append(tokens[i][:-1])
    
    elif len(tokens[i])>1 and "." in tokens[i]:
      # "embarrassment.santorum" --> "embarrassment", "santorum"
      for w in tokens[i].split("."):
        if w.strip():
          cleaned.append(w)
    
    elif tokens[i] not in string.punctuation and tokens[i].strip() \
    and tokens[i].islower():
      # append word, ignoring single punct
      cleaned.append(tokens[i])

    i += 1
  return cleaned

"""
[removeStopwords] removes stopwords defined by nltk package.
Precondition: [tokens] is a list of lowercased and tokenized words.
Returns: a list of word tokens without stopwords.
"""
def removeStopwords(tokens): 
  stopWords = set(stopwords.words("english")) 
  filtered = [w for w in tokens if w not in stopWords] 
  return filtered 

from collections import Counter

####### 2 alternative methods of handling unknown words ########

"""
METHOD 1: first occurance of any word in [processed] = <UNK>.
Requires: [processed] is preprocessed.
Returns: a list of lists with all first occurances of the words replaced by 
<UNK>.
"""
def first_occur(processed):
  vocab = {"<UNK>", "<s>", "</s>"}
  # loop through dataset
  handled = []
  for sublist in processed:
    sl = []
    for item in sublist:
      if item not in vocab:
        sl.append("<UNK>")
        vocab.add(item)
      else:
        sl.append(item)
    handled.append(sl)

  return handled   
  
"""
METHOD 2: creates a vocabulary with top [k]% common words in [processed], 
any OOV words = <UNK>.
Requires: k > 0 && k <= 1.
Returns: a list of lists with all OOV words replaced by <UNK>.
"""
def top_k(processed, top):
  # get count dict
  fd = countDict(processed)
  vocabSize = int(len(fd)*top+0.5)
  c = Counter(fd)
  vocabSet = toSet(c.most_common(vocabSize))
  vocabSet.add('<s>')
  vocabSet.add('</s>')

  # loop through dataset
  handled = []
  for sublist in processed:
    sl = []
    for item in sublist:
      if item not in vocabSet:
        sl.append("<UNK>")
      else:
        sl.append(item)
    handled.append(sl)

  return handled

"""
[toSet] transforms the vocabulary generated by Counter to a set.
Returns: a set of word types.
Example:
[('b', 7), ('c', 1)] --> {'b','c'}.
"""
def toSet(vocab):
  vSet = set()
  for word, count in vocab:
    vSet.add(word)
  return vSet

"""
[countDict] returns a dictionary with a word type as key and its count as value.
Requires: [dataset] is preprocessed.
"""
def countDict(processed):
  # flatten the dataset to a single list
  flatList = []
  for sublist in processed:
    for item in sublist:
        flatList.append(item)
  # count
  fDict = {}
  for w in flatList:
    if w in fDict:
      fDict[w] += 1
    else:
      fDict[w] = 1
  return fDict
